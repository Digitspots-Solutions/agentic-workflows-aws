AWS AI Competency - Customer Case Study
Section 2: Customer Example Details (LAUTECH)

Customer Name: Ladoke Akintola University of Technology (LAUTECH)
Industry: Education / Higher Education
Market Segment: Enterprise

--------------------------------------------------------------------------------
PART A: Common Customer Example Requirements (UCR, PS, CO)
--------------------------------------------------------------------------------

UCR-001: About the Customer
Ladoke Akintola University of Technology (LAUTECH) is a public university in Nigeria serving over 10,000 undergraduate and postgraduate students. The university operates multiple faculties including Engineering, Environmental Sciences, and Management Sciences. This project specifically addresses the Student Affairs and Academic Registry departments.

UCR-002: Key Business Challenge
The university faced severe operational bottlenecks during peak academic periods (semester registration and examination windows).
1. Volume: Minimal IT staff were overwhelmed by thousands of repetitive in-person and email queries.
2. Latency: Response times for routine inquiries (course details, fees, schedules) averaged 24-48 hours.
3. Consistency: Information fragmentation across departments led to inconsistent guidance provided to students.
4. Scale: The existing support infrastructure could not scale to meet 24/7 demand from a digital-native student body.

UCR-003: Goals and Objectives
Business Goals:
- Reduce routine query response time from hours to <5 seconds.
- Achieve 24/7 service availability for critical academic information.
- Redirect 60% of support staff time from repetitive FAQs to complex student issues.

Technical Goals:
- Deploy a scalable, serverless AI solution on AWS.
- Integrate securely with the existing PostgreSQL student information database.
- Ensure strict data privacy and content safety standards.

UCR-004: Designation Definition Fit (Agentic AI Consulting Services)
This implementation exemplifies Agentic AI Consulting Services by deploying an autonomous multi-agent system that goes beyond simple retrieval. The solution:
1. Plans: Dissects complex multi-part student queries (e.g., "What are the fees for 100 level and which courses do I take?").
2. Reasons: Determines the correct sequence of tool invocations (Finance Tool -> Course Tool).
3. Executes: Autonomously queries backend databases and synthesizes the results into a coherent response.
This aligns with the competency definition of designing and implementing extensive agentic workflows.

PS-001: Technical Solution
We architectural a Multi-Agent Orchestrator pattern using the Strands Agents SDK on Amazon Bedrock.
- Orchestrator: A central agent utilizes Claude 3.5 Haiku to interpret intent and route tasks.
- Specialist Tools: Four discrete tools were built for Course Info, Finance, Calendar, and Hostels.
- Data Layer: Amazon RDS for PostgreSQL serves as the source of truth.
- State Management: Bedrock AgentCore Memory maintains session context (STM/LTM).
- Interface: Accessible via a secure Web Dashboard (Streamlit on ECS Fargate) and WhatsApp.

PS-002: Solution Optimality
The multi-agent approach was selected over alternative designs:
1. vs. Rule-Based Chatbots: Provides flexibility for unstructured natural language queries that rule engines fail to parse.
2. vs. Monolithic LLM: Decentralizing knowledge into tools ensures higher accuracy (grounding) and reduces hallucinations compared to relying solely on model training data.
3. vs. Amazon Lex: While Lex is powerful for intent classification, the Strands/Bedrock combination offered superior reasoning capabilities for complex, multi-turn conversations requiring context retention.

PS-003: Production Status and AWS Usage
Status: Live in Production
AgentCore Runtime ARN: arn:aws:bedrock-agentcore:us-east-1:715841330456:runtime/lautech_agentcore-KLZaaW7AR6
Estimated ARR: $200-$500/year (based on usage volume)

CO-001: Key Performance Indicators (KPIs)
1. Response Latency:
   - Baseline: 24+ hours (Manual)
   - Target: <5 seconds
   - Achieved: <3 seconds average via Bedrock Claude 3.5 Haiku.

2. Service Availability:
   - Baseline: 8 hours/day (Business Hours)
   - Achieved: 99.9% (24/7 Availability via Serverless Architecture).

3. Automation Rate:
   - 70% of routine queries are now fully handled by the AI agent without human intervention.

CO-002: Continuous Improvement
- Challenge: Initial "cold start" latency for the first query in a session.
- Mitigation: Implemented response caching for frequently asked questions at the application layer.
- Challenge: Database connection saturation during load testing.
- Improvement: Optimized SQL queries and implemented connection pooling in the production deployment.

--------------------------------------------------------------------------------
PART B: Agentic AI Specific Customer Requirements (AGAIPS)
--------------------------------------------------------------------------------

AGAIPS-001: Agentic AI Practice Implementation Approach
The solution architecture follows the AWS Well-Architected Framework for AI agents.
- Model: Claude 3.5 Haiku was chosen for its high throughput and low cost-per-token, essential for a public-facing university service.
- Framework: Strands Agents SDK provides native integration with Bedrock AgentCore, simplifying the deployment pipeline compared to containerized LangChain solutions.
Evidence: See attached Architecture Diagram (LAUTECH_Architecture_Guide.pdf).

AGAIPS-002: Security and Interoperability Practice
- Identity: Applications authenticate via AgentCore Session IDs. User identity is tracked via "actor_id" in the session context.
- Authorization: IAM Roles follow least-privilege principles. The AgentCore execution role has permission only to invoke specific Lambda functions and read specific Secrets.
- Data Security: All sensitive database credentials are stored in AWS Secrets Manager. No static keys exist in the codebase.
Evidence: See Security Section in Architecture Guide.

AGAIPS-003: Responsible AI Practice
A comprehensive Responsible AI framework was implemented:
1. Controls: Amazon Bedrock Guardrails are active with high thresholds for harmful content.
2. Privacy: PII (emails, phone numbers) is redacted from model inputs/outputs.
3. Safety: Topic blocking is enabled for political, religious, and illegal content to maintain academic neutrality.
Evidence: See attached Responsible AI Guide (01_Practice_Requirements_QCHK.txt).

AGAIPS-004: Compute Practice
The solution leverages purely managed services to minimize operational overhead for the university API.
1. Compute: Amazon Bedrock AgentCore (Serverless).
2. Hosting: AWS ECS Fargate (Serverless Containers).
3. Database: Amazon RDS (Managed Database).
This architecture ensures automatic scaling during registration peaks without manual provisioning.
Evidence: See Architecture Diagram.
